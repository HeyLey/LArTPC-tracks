{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import tables\n",
    "from random import shuffle\n",
    "from IPython.display import clear_output\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "USE_GPU = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3' if USE_GPU else ''\n",
    "EPS = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for phase 1 set num_classes=3\n",
    "# for phase 2 set num_classes=4\n",
    "num_classes = 4\n",
    "\n",
    "energy_cut = 0.0099999985 #0.01\n",
    "zero_class_exists = False\n",
    "\n",
    "num_nn_output = num_classes - (not zero_class_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = '/home/leyla/data/train_5-6.csv'\n",
    "#train_file2 = '/home/leyla/data/train_3-4.csv'\n",
    "test_file = '/home/leyla/data/test_5-6.csv'\n",
    "submission_file = '/home/leyla/data/submission_simplified_5-6.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a = pd.read_csv(train_file1) \n",
    "#b = pd.read_csv(train_file2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b['event'] += 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b = b.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merged = a.append(b)\n",
    "#merged.to_csv('/home/leyla/data/output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_file = '/home/leyla/data/output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tr = pd.read_csv(train_file)\n",
    "#tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/leyla/baseline_mpnn/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.base import plot_3d, hdf5_to_numpy, plot_3d_with_edges, csv_to_numpy, X_MAX, Y_MAX, Z_MAX\n",
    "from tools.tools import stretch_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1245269775390625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.memory_info().rss / 2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 4.36 s, total: 25.8 s\n",
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, Y, M, _ = csv_to_numpy(file=train_file, num_classes=num_classes, \n",
    "                               zero_class_exists=zero_class_exists, energy_cut=energy_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = -2\n",
    "#plot_3d(X[k], Y[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = 80\n",
    "mode = 'kneighbors_graph' #'radius_neighbors_graph' \n",
    "\n",
    "in_degree_max, out_degree_max = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.simplified_clustering import generate_graph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:54<00:00, 16.99it/s]\n"
     ]
    }
   ],
   "source": [
    "X_clusters_graph = []\n",
    "lx = len(X)\n",
    "for k in tqdm(range(lx)):\n",
    "    if len(X[k]) == 0:\n",
    "        continue\n",
    "    # construction of graph based on aggregated statistics\n",
    "    X_cluster_graph, in_degree_max_local, out_degree_max_local = generate_graph_dataset(X=X[k], Y=Y[k], M=M[k],\n",
    "                                                                                       n_neighbors=n_neighbors,\n",
    "                                                                                       mode = mode\n",
    "                                                                                       )\n",
    "    in_degree_max = max(in_degree_max_local, in_degree_max)\n",
    "    out_degree_max = max(out_degree_max_local, out_degree_max)\n",
    "    \n",
    "    X_clusters_graph.append(X_cluster_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#k = 0\n",
    "#plot_3d_with_edges(X[k], Y[k], X_clusters_graph[k]['X_cluster_in_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_degree_max, out_degree_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padding\n",
    "for X_cluster_graph in X_clusters_graph:\n",
    "    X_cluster_graph['X_cluster_messages_out'] = stretch_array(X_cluster_graph['X_cluster_messages_out'], \n",
    "                                                              n=out_degree_max, \n",
    "                                                              fill_value=len(X_cluster_graph['X_cluster_edges']))\n",
    "    \n",
    "    X_cluster_graph['X_cluster_messages_in'] = stretch_array(X_cluster_graph['X_cluster_messages_in'], \n",
    "                                                              n=in_degree_max, \n",
    "                                                              fill_value=len(X_cluster_graph['X_cluster_edges']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning model (MPNN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.activations import relu\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2099, 1), (405638, 5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cluster_graph['X_cluster_nodes'].shape, X_cluster_graph['X_cluster_edges'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__X_nodes__ -- features per hit(i.e. energy).\n",
    "\n",
    "__X_edges__ -- features for each edge that connects two hits(i.e. relative difference of coordinates).\n",
    "\n",
    "__X_labels__ -- labels ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndim_features_nodes = 4\n",
    "ndim_features_edges = 5 \n",
    "ndim_message = 6\n",
    "\n",
    "X_nodes = K.placeholder(shape=(None, ndim_features_nodes)) # features of nodes\n",
    "X_edges = K.placeholder(shape=(None, ndim_features_edges)) # features of edges\n",
    "X_labels = K.placeholder(shape=(None, num_nn_output)) # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__X_nodes_in_out__ -- edge list.\n",
    "\n",
    "__X_messages_in__ -- in-adjacency lists.\n",
    "\n",
    "__X_messages_out__ -- out-adjacency lists.\n",
    "\n",
    "All these graph representations are equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_nodes_in_out = K.placeholder(shape=(None, 2), dtype=np.int32) # edges\n",
    "X_messages_in = K.placeholder(shape=(None, in_degree_max), dtype=np.int32) # shape = (none, size of neighbourhood)\n",
    "X_messages_out = K.placeholder(shape=(None, out_degree_max), dtype=np.int32) # shape = (none, size of neighbourhood)\n",
    "\n",
    "# fake messages to(or from) non-existing node\n",
    "fake_message_const = K.constant(value=[ndim_message * [-np.inf]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeholders = {\n",
    "    'X_nodes': X_nodes,\n",
    "    'X_edges': X_edges,\n",
    "    'X_labels': X_labels,\n",
    "    'X_nodes_in_out': X_nodes_in_out,\n",
    "    'X_messages_in': X_messages_in,\n",
    "    'X_messages_out': X_messages_out\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 8 #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 6\n",
    "\n",
    "message_passers = {\n",
    "    0: Sequential(layers=[\n",
    "                      Dense(64, input_shape=(2 * ndim_features_nodes + ndim_features_edges,), activation=relu), \n",
    "                     # Dropout(rate=0.05),\n",
    "                      Dense(ndim_message, activation=relu), #,\n",
    "                    #  Dropout(rate=0.05),\n",
    "                  ]\n",
    "                 ),\n",
    "    1: Sequential(layers=[\n",
    "                      Dense(64, input_shape=(2 * ndim_features_nodes + ndim_features_edges,), activation=relu), \n",
    "                    #  Dropout(rate=0.05),\n",
    "                      Dense(ndim_message, activation=relu), #,\n",
    "                    #  Dropout(rate=0.05),\n",
    "                  ]\n",
    "                 ),    \n",
    "    2: Sequential(layers=[\n",
    "                      Dense(64, input_shape=(2 * ndim_features_nodes + ndim_features_edges,), activation=relu), \n",
    "                     # Dropout(rate=0.05),\n",
    "                      Dense(ndim_message, activation=relu) ,\n",
    "                    #  Dropout(rate=0.05),\n",
    "                  ]\n",
    "                 ),\n",
    "    3: Sequential(layers=[\n",
    "                      Dense(64, input_shape=(2 * ndim_features_nodes + ndim_features_edges,), activation=relu), \n",
    "                    #  Dropout(rate=0.05),\n",
    "                      Dense(ndim_message, activation=relu) ,\n",
    "                    #  Dropout(rate=0.05),\n",
    "                  ]\n",
    "                 ),\n",
    "    4: Sequential(layers=[\n",
    "                      Dense(64, input_shape=(2 * ndim_features_nodes + ndim_features_edges,), activation=relu), \n",
    "                    #  Dropout(rate=0.05),\n",
    "                      Dense(ndim_message, activation=relu) ,\n",
    "                   #   Dropout(rate=0.05),\n",
    "                  ]\n",
    "                 ),\n",
    "     5: Sequential(layers=[\n",
    "                      Dense(64, input_shape=(2 * ndim_features_nodes + ndim_features_edges,), activation=relu), \n",
    "                    #  Dropout(rate=0.05),\n",
    "                      Dense(ndim_message, activation=relu) ,\n",
    "                   #   Dropout(rate=0.05),\n",
    "                  ]\n",
    "                 )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#state_updater = tf.contrib.rnn.LSTMCell(num_units=ndim_features_nodes)\n",
    "#state_updater = tf.contrib.rnn.GRUCell(num_units=ndim_features_nodes)\n",
    "state_updater = Sequential(layers=[\n",
    "                     Dense(32, input_shape=(m * ndim_message + ndim_features_nodes,), activation=relu), \n",
    "                     Dense(ndim_features_nodes)\n",
    "                                 ]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#readout = Dense(num_nn_output, input_shape=(ndim_features_nodes,), activation=keras.activations.softmax)\n",
    "\n",
    "readout = Sequential(layers=[\n",
    "                     Dense(64, input_shape=(ndim_features_nodes,), activation=relu),\n",
    "                     Dense(num_nn_output, activation=keras.activations.softmax)\n",
    "                                 ]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNN construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.mpnn import build_network, run_train, run_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predictions = build_network(X_nodes=X_nodes, \n",
    "                              X_edges=X_edges, \n",
    "                              X_nodes_in_out=X_nodes_in_out, \n",
    "                              X_messages_in=X_messages_in, \n",
    "                              X_messages_out=X_messages_out, \n",
    "                              message_passers=message_passers, \n",
    "                              state_updater=state_updater, \n",
    "                              readout=readout, \n",
    "                              steps=steps, \n",
    "                              ndim_features_nodes=ndim_features_nodes,\n",
    "                              fake_message_const=fake_message_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tf = tf.reduce_mean(keras.losses.categorical_crossentropy(X_labels, X_predictions))\n",
    "accuracy_tf = tf.reduce_mean(keras.metrics.categorical_accuracy(X_labels, X_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss_tf, var_list=tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "init.run(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = int(len(X_clusters_graph) * 0.9)\n",
    "print(TRAIN_SIZE)\n",
    "shuffle(X_clusters_graph)\n",
    "\n",
    "X_clusters_graph_train = X_clusters_graph[:TRAIN_SIZE]\n",
    "X_clusters_graph_eval = X_clusters_graph[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4995,1258,6] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_46 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](GatherV2_101, Mean_116)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_123/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4220_Mean_123\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'sub_46', defined at:\n  File \"/opt/conda/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-aec33d7d5296>\", line 11, in <module>\n    fake_message_const=fake_message_const)\n  File \"/home/leyla/baseline_mpnn/tools/mpnn.py\", line 28, in build_network\n    messages_aggregated_out3 = K.var(K.gather(reference=messages, indices=X_messages_out), axis=1)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1259, in var\n    devs_squared = tf.square(x - m)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8009, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4995,1258,6] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_46 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](GatherV2_101, Mean_116)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_123/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4220_Mean_123\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4995,1258,6] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_46 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](GatherV2_101, Mean_116)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_123/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4220_Mean_123\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-cbe8b7576fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                    \u001b[0mndim_features_edges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim_features_edges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                    \u001b[0mplaceholders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplaceholders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                    metrics=[loss_tf, accuracy_tf])\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlosses_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0maccuracies_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leyla/baseline_mpnn/tools/mpnn.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(X_cluster_graph, X_predictions, optimizer, sess, ndim_features_nodes, ndim_features_edges, placeholders, metrics)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mplaceholders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_messages_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_cluster_graph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_cluster_messages_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mplaceholders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_messages_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_cluster_graph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_cluster_messages_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     })\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4995,1258,6] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_46 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](GatherV2_101, Mean_116)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_123/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4220_Mean_123\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'sub_46', defined at:\n  File \"/opt/conda/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-aec33d7d5296>\", line 11, in <module>\n    fake_message_const=fake_message_const)\n  File \"/home/leyla/baseline_mpnn/tools/mpnn.py\", line 28, in build_network\n    messages_aggregated_out3 = K.var(K.gather(reference=messages, indices=X_messages_out), axis=1)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1259, in var\n    devs_squared = tf.square(x - m)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8009, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4995,1258,6] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_46 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](GatherV2_101, Mean_116)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_123/_353 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4220_Mean_123\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "roc_aucs = []\n",
    "n = 15\n",
    "\n",
    "for epoch in tqdm(range(n)):\n",
    "    loss_float = 0\n",
    "    accuracy_float = 0\n",
    "    \n",
    "    losses_epoch = []\n",
    "    accuracies_epoch = []\n",
    "    roc_aucs_epoch = []\n",
    "    for X_cluster_graph in X_clusters_graph_train:\n",
    "        predictions, (loss, accuracy) = run_train(X_cluster_graph=X_cluster_graph,\n",
    "                                   X_predictions=X_predictions,\n",
    "                                   optimizer=optimizer, sess=sess, \n",
    "                                   ndim_features_nodes=ndim_features_nodes, \n",
    "                                   ndim_features_edges=ndim_features_edges, \n",
    "                                   placeholders=placeholders,\n",
    "                                   metrics=[loss_tf, accuracy_tf])\n",
    "        losses_epoch.append(loss)\n",
    "        accuracies_epoch.append(accuracy)\n",
    "    clear_output()\n",
    "    \n",
    "    losses.append(np.mean(losses_epoch))\n",
    "    plt.title('log-loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "    accuracies.append(np.mean(accuracies_epoch))\n",
    "    plt.title('accuracy')\n",
    "    plt.plot(accuracies)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses_test = [] \n",
    "accuracies_test = [] \n",
    "roc_aucs_test = [] \n",
    "predictions_total = [] \n",
    "y_total =[]\n",
    "\n",
    "for X_cluster_graph in X_clusters_graph_eval: \n",
    "    predictions = run_test(X_cluster_graph=X_cluster_graph, \n",
    "                           X_predictions=X_predictions, \n",
    "                           sess=sess, \n",
    "                           ndim_features_nodes=ndim_features_nodes, \n",
    "                           ndim_features_edges=ndim_features_edges, \n",
    "                           placeholders=placeholders) \n",
    "    X_cluster_graph['predictions'] = predictions \n",
    "    predictions_total.append(predictions) \n",
    "    y_total.append(X_cluster_graph['Y_cluster_labels']) \n",
    "    losses_test.append(loss) \n",
    "    accuracies_test.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#losses_test = []\n",
    "#accuracies_test = []\n",
    "#roc_aucs_test = []\n",
    "#predictions_total = [] \n",
    "#y_total =[]\n",
    "\n",
    "#for X_cluster_graph in X_clusters_graph_eval:\n",
    " #   predictions, (loss, accuracy) = run_test(X_cluster_graph=X_cluster_graph, \n",
    "  #                                            X_predictions=X_predictions,\n",
    "   #                                           sess=sess, \n",
    "    #                                          ndim_features_nodes=ndim_features_nodes, \n",
    "     #                                         ndim_features_edges=ndim_features_edges, \n",
    "      #                                        placeholders=placeholders,\n",
    "       #                                       metrics=[loss_tf, accuracy_tf])\n",
    " #   X_cluster_graph['predictions'] = predictions\n",
    "  #  predictions_total.append(predictions)\n",
    "   # y_total.append(X_cluster_graph['Y_cluster_labels'])\n",
    "    #losses_test.append(loss)\n",
    "    #accuracies_test.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_total = np.concatenate(predictions_total)\n",
    "y_total = np.concatenate(y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "accuracy = metrics.accuracy_score(np.argmax(y_total, axis=1), np.argmax(predictions_total, axis=1))\n",
    "roc_auc = metrics.roc_auc_score(y_total, predictions_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9568560565133952"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy \n",
    "# start -0.8683611126422625\n",
    "# use gru - 0.8687567396308694\n",
    "# neib = 30 - 0.8910923820501319\n",
    "# neib = 40 - 0.9082779642419363\n",
    "# neib = 45 - 0.9158992339666193\n",
    "# epoch = 20 - 0.9206353632299216\n",
    "# epoch = 25 neib = 50 - 0.9264679126592279\n",
    "# LSTM - 0.9237462378528039\n",
    "# data 14xxx - 0.9292922456499576\n",
    "# data 14xxx neib =30 0.9140251065371974 \n",
    "# data 5000 neib = 30 layers = 15 - 0.9060545732807426\n",
    "# neib - 60 + k_mean - 0.9299395850343464\n",
    "# energy 0.095 neib 20 ep 10 k_mean- 0.9069938532462544\n",
    "# energy 0.095 neib 60 ep 20 k_mean 0.9315556814741793 bad bad bad\n",
    "# fec 8 0.932470521438493 \n",
    "#fec 12 0.9401650911552497 \n",
    "# dataset 14xxx 0.9396454244919843  # ds 5xxx 0.9437540667624275 # 0.9413805860665672 #0.9496136479567739 \n",
    "#0.9505675006817211\n",
    "#0.9568560565133952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950754738272782"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc \n",
    "# 0.9666363977125328\n",
    "# 0.9633168628170781\n",
    "# 0.973642993604225\n",
    "# 0.9809168220142711\n",
    "# 0.9833718768518708\n",
    "# 0.9848123191935816\n",
    "# 0.98685898792743\n",
    "# 0.9861728000922451\n",
    "# 0.9876960468540009\n",
    "# 0.9882631114162708\n",
    "# 0.9882631114162708\n",
    "# 0.9892055238144396\n",
    "# 0.9825319454860798\n",
    "# 0.9898732963738727\n",
    "# 0.9895222142393605  \n",
    "#0.990904425606832\n",
    "#0.9919523564090716\n",
    "# 0.9925245011296729\n",
    "#0.9931252926811585 #0.9936682934108406 #0.9950754738272782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/leyla/data/test_5-6.csv'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test, M_test, events_test = csv_to_numpy(file=test_file, num_classes=num_classes, test=True,\n",
    "                                                   zero_class_exists=zero_class_exists, energy_cut=energy_cut)\n",
    "shift = 0 if zero_class_exists else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [24:11<00:00,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import tables\n",
    "preds_array = []\n",
    "\n",
    "for k, event in tqdm(list(enumerate(events_test))):\n",
    "        X_cluster_graph, in_degree_max_local, out_degree_max_local = generate_graph_dataset(X=X_test[k], \n",
    "                                                                                            Y=Y_test[k], \n",
    "                                                                                            M=M_test[k],\n",
    "                                                                                            n_neighbors=n_neighbors, \n",
    "                                                                                            in_degree_max=in_degree_max, \n",
    "                                                                                            out_degree_max=out_degree_max)\n",
    "        \n",
    "        predictions = run_test(X_cluster_graph=X_cluster_graph, \n",
    "                                               X_predictions=X_predictions,\n",
    "                                               sess=sess, \n",
    "                                               ndim_features_nodes=ndim_features_nodes, \n",
    "                                               ndim_features_edges=ndim_features_edges, \n",
    "                                               placeholders=placeholders)\n",
    "        preds_array.append(pd.DataFrame.from_dict(\n",
    "            {\n",
    "                'x': (X_test[k][:, 0] * X_MAX).astype(int), \n",
    "                'y': (X_test[k][:, 1] * Y_MAX).astype(int), \n",
    "                'z': (X_test[k][:, 2] * Z_MAX).astype(int),\n",
    "                'event': event, \n",
    "                'pred': np.argmax(predictions, axis=1) + shift,\n",
    "        }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_df = pd.concat(preds_array)  \n",
    "\n",
    "preds_df.to_csv(submission_file, index=False)\n",
    "#preds_array.close()\n",
    "#f_submission.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.11070251464844"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.memory_info().rss / 2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
